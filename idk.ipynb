{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import h5py\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "## Loading images and labels\n",
    "(train_ds, train_labels), (test_ds, test_labels) = tfds.load(\n",
    "    \"tf_flowers\",\n",
    "    split=[\"train[:70%]\", \"train[:30%]\"], ## Train test split\n",
    "    batch_size=-1,\n",
    "    as_supervised=True,  # Include labels\n",
    ")\n",
    "\n",
    "## Resizing images\n",
    "train_ds = tf.image.resize(train_ds, (150, 150))\n",
    "test_ds = tf.image.resize(test_ds, (150, 150))\n",
    "\n",
    "## Transforming labels to correct format\n",
    "train_labels = to_categorical(train_labels, num_classes=5)\n",
    "test_labels = to_categorical(test_labels, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([150, 150, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Dense, Input,concatenate\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467096/553467096 [==============================] - 596s 1us/step\n"
     ]
    }
   ],
   "source": [
    "vgg16 = tf.keras.applications.VGG16(weights='imagenet', include_top=True, pooling='max', input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x0000029ECBB40490> True\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029ECC9C5460> True\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029ECC9C56D0> True\n",
      "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x0000029ECCAA8190> True\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029ECC9C59D0> True\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029ECCAEC250> True\n",
      "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x0000029ECCBF6EE0> True\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029ECCBF6A30> True\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029ECCAECA30> True\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029ECCC05EB0> True\n",
      "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x0000029ECCC05850> True\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029ECCC05B80> True\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029ECCAEC310> True\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029ECC9C5AF0> True\n",
      "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x0000029ECCAA8BE0> True\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029ECC9C5AC0> True\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029ECCC16B50> True\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029ECCC164F0> True\n",
      "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x0000029ECCC1BFD0> True\n",
      "<keras.layers.reshaping.flatten.Flatten object at 0x0000029ECCC16730> True\n",
      "<keras.layers.core.dense.Dense object at 0x0000029ECCC20B50> True\n",
      "<keras.layers.core.dense.Dense object at 0x0000029ECCC20EE0> True\n",
      "<keras.layers.core.dense.Dense object at 0x0000029ECCC20280> True\n"
     ]
    }
   ],
   "source": [
    "for layer in vgg16.layers:\n",
    "\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel = Model(inputs=vgg16.input, outputs=vgg16.get_layer('fc2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "def get_feature_vector(img):\n",
    "    img1 = cv2.resize(img, (224, 224))\n",
    "\n",
    "    image = img_to_array(image)\n",
    "\n",
    "    # reshape data for the model\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "\n",
    "    from keras.applications.vgg16 import preprocess_input\n",
    "    # prepare the image for the VGG model\n",
    "    image = preprocess_input(image)\n",
    "    feature_vector = basemodel.predict(img1.reshape(1, 224, 224, 3))\n",
    "    \n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(vector1, vector2):\n",
    " return 1 - spatial.distance.cosine(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_feature_vector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Vizuamatix\\Neural Network\\idk.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Vizuamatix/Neural%20Network/idk.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m img2 \u001b[39m=\u001b[39m load_img(\u001b[39m\"\u001b[39m\u001b[39mNew folder/test/dove_body_wash.jpg\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Vizuamatix/Neural%20Network/idk.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m img3 \u001b[39m=\u001b[39m load_img(\u001b[39m\"\u001b[39m\u001b[39mNew folder/test/test.png\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Vizuamatix/Neural%20Network/idk.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m f1 \u001b[39m=\u001b[39m get_feature_vector(img1)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Vizuamatix/Neural%20Network/idk.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m f2 \u001b[39m=\u001b[39m get_feature_vector(img2)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Vizuamatix/Neural%20Network/idk.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m f3 \u001b[39m=\u001b[39m get_feature_vector(img3)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_feature_vector' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "\n",
    "img1 = load_img(\"New folder/test/dove_body_wash_pink.jpg\")\n",
    "img2 = load_img(\"New folder/test/dove_body_wash.jpg\")\n",
    "img3 = load_img(\"New folder/test/test.png\")\n",
    "f1 = get_feature_vector(img1)\n",
    "f2 = get_feature_vector(img2)\n",
    "f3 = get_feature_vector(img3)\n",
    "calculate_similarity(f1, f2)\n",
    "calculate_similarity(f1, f3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a90aeebcf29d64a654773811cc170cb25061cb2498f10ac689db374c7bf325de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
