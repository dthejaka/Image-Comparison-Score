{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "image_size = 224\n",
    "batch_size_training = 10\n",
    "batch_size_validation = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(preprocessing_function=preprocess_input,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 images belonging to 4 classes.\n",
      "Found 9 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator.flow_from_directory(\n",
    "    'New folder/train',\n",
    "    target_size = (image_size, image_size),\n",
    "    batch_size = batch_size_training,\n",
    "    class_mode = 'categorical'\n",
    "    )\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'New folder/validation',\n",
    "    target_size = (image_size, image_size),\n",
    "    batch_size = batch_size_training,\n",
    "    class_mode = 'categorical'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defingin the model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding VGG16 model\n",
    "from xml.etree.ElementInclude import include\n",
    "\n",
    "\n",
    "model.add(\n",
    "    ResNet50(include_top = False, pooling='avg', weights ='imagenet')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.functional.Functional at 0x2640602e790>,\n",
       " <keras.layers.core.dense.Dense at 0x2647d9584c0>,\n",
       " <keras.layers.core.dense.Dense at 0x2647d945340>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 2048)              23587712  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              8392704   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 16388     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,996,804\n",
      "Trainable params: 31,943,684\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x2647d9584c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of layers\n",
    "model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model\n",
    "model.layers[0].trainable = False\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics =['accuracy'])\n",
    "steps_per_epoch_train = len(train_generator)\n",
    "steps_per_epoch_validation = len(validation_generator)\n",
    "number_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x000002647C51BA30> False\n",
      "<keras.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x000002647C6962B0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647C696550> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647C696A00> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647C696580> False\n",
      "<keras.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x000002647C75E580> False\n",
      "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000002647C7B0A90> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647C8138E0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647C81EB50> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647C813DC0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647C828370> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647C828580> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647C7B0FD0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647C813550> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647C834FA0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647C813D00> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647C830BB0> False\n",
      "<keras.layers.merging.add.Add object at 0x000002647C842D00> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647C842E20> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647C83CDF0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647C84AFA0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647C834F10> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647C8527C0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647C8589D0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647C8524F0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647C858730> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647C8678B0> False\n",
      "<keras.layers.merging.add.Add object at 0x000002647C858820> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647C873D00> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647C86A8B0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647C877970> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647C877850> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647C883400> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647C883880> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647C873AC0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647C890FD0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647C8901C0> False\n",
      "<keras.layers.merging.add.Add object at 0x000002647C89E130> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647C897AF0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647C88A520> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647C8587C0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647C88A190> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647C8288E0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647C830610> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647C828CA0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647C88A970> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647C86D9A0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647C8770D0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647C86D280> False\n",
      "<keras.layers.merging.add.Add object at 0x000002647C8AC6A0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647C8ACA60> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647C86D880> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D881850> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D887EE0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D8871C0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D88CFA0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D881490> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D88C340> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D899B20> False\n",
      "<keras.layers.merging.add.Add object at 0x000002647D892F70> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D8A1CA0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D8A73D0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D8AD250> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D88C850> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D8AD0D0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D8B6D00> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D8AD640> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D8BB1F0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D8C8BB0> False\n",
      "<keras.layers.merging.add.Add object at 0x000002647D8B6760> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D8D0E50> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D8C8B20> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D8D7BE0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D8D7AC0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D8DFAF0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D8E65B0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D8ED430> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D8E6EB0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D8E6A00> False\n",
      "<keras.layers.merging.add.Add object at 0x000002647D8A7070> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D8A75E0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647C86A520> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647C75E9A0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D8C2670> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D8F14F0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D8F1EE0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647C8A3AC0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D899280> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D8F7EB0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D887C70> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D8FAF10> False\n",
      "<keras.layers.merging.add.Add object at 0x000002647D901970> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D901100> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D8FDFD0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D8F77C0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D8FAE50> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D9079D0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D90E970> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D9076D0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D901CD0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D91C820> False\n",
      "<keras.layers.merging.add.Add object at 0x000002647D914C10> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D929C70> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D9227F0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D930940> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D930820> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D9393A0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D9391C0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D922940> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D929B20> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D929850> False\n",
      "<keras.layers.merging.add.Add object at 0x000002647D9540A0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D954820> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D958430> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D95D370> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D95DE50> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D95D880> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D94DAC0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D9222B0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D93EE80> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D958CA0> False\n",
      "<keras.layers.merging.add.Add object at 0x000002647D94D8B0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647C83C370> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647C8AB550> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D8E6E20> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D8F7670> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D8B6190> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D96E8E0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D8C8040> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D8F2BE0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D970790> False\n",
      "<keras.layers.merging.add.Add object at 0x000002647D96E5E0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D979AF0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D9750D0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D97E880> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D985F10> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D985D00> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D98B940> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D985190> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D990F40> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D997B50> False\n",
      "<keras.layers.merging.add.Add object at 0x000002647D990FA0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D99F190> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D99F1F0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D9B31C0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D98BD90> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D9A53A0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D985EB0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D899A30> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D9A52E0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x00000264060102B0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D9A9280> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000026406010E20> False\n",
      "<keras.layers.merging.add.Add object at 0x0000026406022880> False\n",
      "<keras.layers.core.activation.Activation object at 0x0000026406022130> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000026406017FD0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000026406017DF0> False\n",
      "<keras.layers.core.activation.Activation object at 0x0000026406000F10> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000026406006640> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000026406006E50> False\n",
      "<keras.layers.core.activation.Activation object at 0x0000026406000490> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D990C10> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000264711387F0> False\n",
      "<keras.layers.merging.add.Add object at 0x000002647D99FE50> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D96E280> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D8F2B50> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D96EBB0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D979B80> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002647D98B700> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002647D9142E0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D929700> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002640602E8B0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000026406027700> False\n",
      "<keras.layers.merging.add.Add object at 0x000002647C86D4C0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002647D96E4C0> False\n",
      "<keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x0000026406031D30> False\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers[0].layers:\n",
    "\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_11012\\2980021967.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  fit_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch_train, epochs=number_epochs,verbose=1, validation_data=validation_generator, validation_steps=steps_per_epoch_validation,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 9s 849ms/step - loss: 2.2732 - accuracy: 0.7250 - val_loss: 0.5663 - val_accuracy: 0.8889\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 5s 679ms/step - loss: 0.0492 - accuracy: 0.9625 - val_loss: 0.0017 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "fit_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch_train, epochs=number_epochs,verbose=1, validation_data=validation_generator, validation_steps=steps_per_epoch_validation,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/ResNet50/ResNet50_Product_Classification_2Dense_one_prod.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\Vizuamatix\\Neural Network\\new.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Vizuamatix/Neural%20Network/new.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#save the model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Vizuamatix/Neural%20Network/new.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "#save the model\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "ResNet50_saved = load_model('model/ResNet50/ResNet50_Product_Classification_2Dense_one_prod.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x2992104f940>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResNet50_saved.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 2048)              23587712  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              8392704   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 16388     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,996,804\n",
      "Trainable params: 8,409,092\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ResNet50_saved.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 941ms/step\n"
     ]
    }
   ],
   "source": [
    "#predicting\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "# load an image from file\n",
    "image = load_img('New folder/test/test.png', target_size=(224, 224))\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image = img_to_array(image)\n",
    "\n",
    "# reshape data for the model\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "# prepare the image for the VGG model\n",
    "image = preprocess_input(image)\n",
    "\n",
    "# predict the probability across all output classes\n",
    "yhat = ResNet50_saved.predict(image)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.9999976e-01, 8.0185835e-08, 3.9740991e-16, 1.4666466e-07],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "basemodel = Model(inputs=ResNet50_saved.input, outputs=ResNet50_saved.get_layer('dense').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 892ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n"
     ]
    }
   ],
   "source": [
    "#predicting\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "# load an image from file\n",
    "image1 = load_img('New folder/test/test4.jpg', target_size=(224, 224))\n",
    "image2 = load_img('New folder/test/test3.png', target_size=(224, 224))\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image1 = img_to_array(image1)\n",
    "image2 = img_to_array(image2)\n",
    "\n",
    "# reshape data for the model\n",
    "image1 = image1.reshape((1, image1.shape[0], image1.shape[1], image1.shape[2]))\n",
    "image2 = image2.reshape((1, image2.shape[0], image2.shape[1], image2.shape[2]))\n",
    "\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "# prepare the image for the VGG model\n",
    "image1 = preprocess_input(image1)\n",
    "image2 = preprocess_input(image2)\n",
    "\n",
    "# predict the probability across all output classes\n",
    "yhat1_base = basemodel.predict(image1)\n",
    "yhat2_base = basemodel.predict(image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.96790206\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "A = yhat1_base[0]\n",
    "B = yhat2_base[0]\n",
    "\n",
    "cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine)\n",
    "\n",
    "#VGG16 - 0.9403707\n",
    "#ResNet50 - 0.9701082"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n"
     ]
    }
   ],
   "source": [
    "#predicting\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "# load an image from file\n",
    "image1 = load_img('New folder/test/test2.jpg', target_size=(224, 224))\n",
    "image2 = load_img('New folder/test/test3.png', target_size=(224, 224))\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image1 = img_to_array(image1)\n",
    "image2 = img_to_array(image2)\n",
    "\n",
    "# reshape data for the model\n",
    "image1 = image1.reshape((1, image1.shape[0], image1.shape[1], image1.shape[2]))\n",
    "image2 = image2.reshape((1, image2.shape[0], image2.shape[1], image2.shape[2]))\n",
    "\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "# prepare the image for the VGG model\n",
    "image1 = preprocess_input(image1)\n",
    "image2 = preprocess_input(image2)\n",
    "\n",
    "# predict the probability across all output classes\n",
    "yhat1_base = basemodel.predict(image1)\n",
    "yhat2_base = basemodel.predict(image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.67621475\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "A = yhat1_base[0]\n",
    "B = yhat2_base[0]\n",
    "\n",
    "cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine)\n",
    "\n",
    "#VGG16 - 0.47206444\n",
    "#ResNet50 - 0.40083203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "Cosine Similarity: 0.8852835\n"
     ]
    }
   ],
   "source": [
    "#predicting\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "# load an image from file\n",
    "image1 = load_img('New folder/test/test.png', target_size=(224, 224))\n",
    "image2 = load_img('New folder/test/test3.png', target_size=(224, 224))\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image1 = img_to_array(image1)\n",
    "image2 = img_to_array(image2)\n",
    "\n",
    "# reshape data for the model\n",
    "image1 = image1.reshape((1, image1.shape[0], image1.shape[1], image1.shape[2]))\n",
    "image2 = image2.reshape((1, image2.shape[0], image2.shape[1], image2.shape[2]))\n",
    "\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "# prepare the image for the VGG model\n",
    "image1 = preprocess_input(image1)\n",
    "image2 = preprocess_input(image2)\n",
    "\n",
    "# predict the probability across all output classes\n",
    "yhat1_base = basemodel.predict(image1)\n",
    "yhat2_base = basemodel.predict(image2)\n",
    "\n",
    "A = yhat1_base[0]\n",
    "B = yhat2_base[0]\n",
    "\n",
    "cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "Cosine Similarity: 0.56222504\n"
     ]
    }
   ],
   "source": [
    "#predicting\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "# load an image from file\n",
    "image1 = load_img('New folder/test/test5.png', target_size=(224, 224))\n",
    "image2 = load_img('New folder/test/test3.png', target_size=(224, 224))\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image1 = img_to_array(image1)\n",
    "image2 = img_to_array(image2)\n",
    "\n",
    "# reshape data for the model\n",
    "image1 = image1.reshape((1, image1.shape[0], image1.shape[1], image1.shape[2]))\n",
    "image2 = image2.reshape((1, image2.shape[0], image2.shape[1], image2.shape[2]))\n",
    "\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "# prepare the image for the VGG model\n",
    "image1 = preprocess_input(image1)\n",
    "image2 = preprocess_input(image2)\n",
    "\n",
    "# predict the probability across all output classes\n",
    "yhat1_base = basemodel.predict(image1)\n",
    "yhat2_base = basemodel.predict(image2)\n",
    "\n",
    "A = yhat1_base[0]\n",
    "B = yhat2_base[0]\n",
    "\n",
    "cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Cosine Similarity: 0.76314044\n"
     ]
    }
   ],
   "source": [
    "#predicting\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "# load an image from file\n",
    "image1 = load_img('New folder/test/test2.jpg', target_size=(224, 224))\n",
    "image2 = load_img('New folder/test/test5.png', target_size=(224, 224))\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image1 = img_to_array(image1)\n",
    "image2 = img_to_array(image2)\n",
    "\n",
    "# reshape data for the model\n",
    "image1 = image1.reshape((1, image1.shape[0], image1.shape[1], image1.shape[2]))\n",
    "image2 = image2.reshape((1, image2.shape[0], image2.shape[1], image2.shape[2]))\n",
    "\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "# prepare the image for the VGG model\n",
    "image1 = preprocess_input(image1)\n",
    "image2 = preprocess_input(image2)\n",
    "\n",
    "# predict the probability across all output classes\n",
    "yhat1_base = basemodel.predict(image1)\n",
    "yhat2_base = basemodel.predict(image2)\n",
    "\n",
    "A = yhat1_base[0]\n",
    "B = yhat2_base[0]\n",
    "\n",
    "cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "Cosine Similarity: 0.92447865\n"
     ]
    }
   ],
   "source": [
    "#predicting\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "# load an image from file\n",
    "image1 = load_img('New folder/test/test6.jpg', target_size=(224, 224))\n",
    "image2 = load_img('New folder/test/test5.png', target_size=(224, 224))\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image1 = img_to_array(image1)\n",
    "image2 = img_to_array(image2)\n",
    "\n",
    "# reshape data for the model\n",
    "image1 = image1.reshape((1, image1.shape[0], image1.shape[1], image1.shape[2]))\n",
    "image2 = image2.reshape((1, image2.shape[0], image2.shape[1], image2.shape[2]))\n",
    "\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "# prepare the image for the VGG model\n",
    "image1 = preprocess_input(image1)\n",
    "image2 = preprocess_input(image2)\n",
    "\n",
    "# predict the probability across all output classes\n",
    "yhat1_base = basemodel.predict(image1)\n",
    "yhat2_base = basemodel.predict(image2)\n",
    "\n",
    "A = yhat1_base[0]\n",
    "B = yhat2_base[0]\n",
    "\n",
    "cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "Cosine Similarity: 0.9828984\n"
     ]
    }
   ],
   "source": [
    "#predicting\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "# load an image from file\n",
    "image1 = load_img('New folder/test/test7.jpeg', target_size=(224, 224))\n",
    "image2 = load_img('New folder/test/test5.png', target_size=(224, 224))\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image1 = img_to_array(image1)\n",
    "image2 = img_to_array(image2)\n",
    "\n",
    "# reshape data for the model\n",
    "image1 = image1.reshape((1, image1.shape[0], image1.shape[1], image1.shape[2]))\n",
    "image2 = image2.reshape((1, image2.shape[0], image2.shape[1], image2.shape[2]))\n",
    "\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "# prepare the image for the VGG model\n",
    "image1 = preprocess_input(image1)\n",
    "image2 = preprocess_input(image2)\n",
    "\n",
    "# predict the probability across all output classes\n",
    "yhat1_base = basemodel.predict(image1)\n",
    "yhat2_base = basemodel.predict(image2)\n",
    "\n",
    "A = yhat1_base[0]\n",
    "B = yhat2_base[0]\n",
    "\n",
    "cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "Cosine Similarity: 0.5496688\n"
     ]
    }
   ],
   "source": [
    "#predicting\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "# load an image from file\n",
    "image1 = load_img('New folder/test/test7.jpeg', target_size=(224, 224))\n",
    "image2 = load_img('New folder/test/test3.png', target_size=(224, 224))\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image1 = img_to_array(image1)\n",
    "image2 = img_to_array(image2)\n",
    "\n",
    "# reshape data for the model\n",
    "image1 = image1.reshape((1, image1.shape[0], image1.shape[1], image1.shape[2]))\n",
    "image2 = image2.reshape((1, image2.shape[0], image2.shape[1], image2.shape[2]))\n",
    "\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "# prepare the image for the VGG model\n",
    "image1 = preprocess_input(image1)\n",
    "image2 = preprocess_input(image2)\n",
    "\n",
    "# predict the probability across all output classes\n",
    "yhat1_base = basemodel.predict(image1)\n",
    "yhat2_base = basemodel.predict(image2)\n",
    "\n",
    "A = yhat1_base[0]\n",
    "B = yhat2_base[0]\n",
    "\n",
    "cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Cosine Similarity: 0.6096772\n"
     ]
    }
   ],
   "source": [
    "#predicting\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "# load an image from file\n",
    "image1 = load_img('New folder/test/test5.png', target_size=(224, 224))\n",
    "image2 = load_img('New folder/test/test4.jpg', target_size=(224, 224))\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image1 = img_to_array(image1)\n",
    "image2 = img_to_array(image2)\n",
    "\n",
    "# reshape data for the model\n",
    "image1 = image1.reshape((1, image1.shape[0], image1.shape[1], image1.shape[2]))\n",
    "image2 = image2.reshape((1, image2.shape[0], image2.shape[1], image2.shape[2]))\n",
    "\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "# prepare the image for the VGG model\n",
    "image1 = preprocess_input(image1)\n",
    "image2 = preprocess_input(image2)\n",
    "\n",
    "# predict the probability across all output classes\n",
    "yhat1_base = basemodel.predict(image1)\n",
    "yhat2_base = basemodel.predict(image2)\n",
    "\n",
    "A = yhat1_base[0]\n",
    "B = yhat2_base[0]\n",
    "\n",
    "cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine)\n",
    "#0.56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a90aeebcf29d64a654773811cc170cb25061cb2498f10ac689db374c7bf325de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
