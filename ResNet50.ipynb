{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "image_size = 224\n",
    "batch_size_training = 10\n",
    "batch_size_validation = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(preprocessing_function=preprocess_input,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 232 images belonging to 4 classes.\n",
      "Found 9 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator.flow_from_directory(\n",
    "    'New folder/train',\n",
    "    target_size = (image_size, image_size),\n",
    "    batch_size = batch_size_training,\n",
    "    class_mode = 'categorical'\n",
    "    )\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'New folder/validation',\n",
    "    target_size = (image_size, image_size),\n",
    "    batch_size = batch_size_training,\n",
    "    class_mode = 'categorical'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defingin the model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 155s 2us/step\n"
     ]
    }
   ],
   "source": [
    "#adding VGG16 model\n",
    "from xml.etree.ElementInclude import include\n",
    "\n",
    "\n",
    "model.add(\n",
    "    ResNet50(include_top = False, pooling='avg', weights ='imagenet')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.functional.Functional at 0x2992096a790>,\n",
       " <keras.layers.core.dense.Dense at 0x299208c0dc0>,\n",
       " <keras.layers.core.dense.Dense at 0x299209004c0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 2048)              23587712  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              8392704   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 16388     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,996,804\n",
      "Trainable params: 31,943,684\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x299208c0dc0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of layers\n",
    "model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model\n",
    "model.layers[0].trainable = False\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics =['accuracy'])\n",
    "steps_per_epoch_train = len(train_generator)\n",
    "steps_per_epoch_validation = len(validation_generator)\n",
    "number_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x000002991947E400> False\n",
      "<keras.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x00000299194D22E0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x00000299194D2580> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000299194D2A30> False\n",
      "<keras.layers.core.activation.Activation object at 0x00000299194D25B0> False\n",
      "<keras.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x000002991967B580> False\n",
      "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x00000299196CEA90> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002991972D8E0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000029919737B50> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002991972DDC0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029919743370> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000029919743580> False\n",
      "<keras.layers.core.activation.Activation object at 0x00000299196CEFD0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002991972D550> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029919751FA0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002991972DD00> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002991974CBB0> False\n",
      "<keras.layers.merging.add.Add object at 0x000002991975FD00> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002991975FE20> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029919758DF0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000029919766FA0> False\n",
      "<keras.layers.core.activation.Activation object at 0x0000029919751F10> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002991976D7C0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000299197759D0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002991976D4F0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029919775730> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000299197838B0> False\n",
      "<keras.layers.merging.add.Add object at 0x0000029919775820> False\n",
      "<keras.layers.core.activation.Activation object at 0x0000029919791D00> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x00000299197878B0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000029919797970> False\n",
      "<keras.layers.core.activation.Activation object at 0x0000029919797850> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002991979E400> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002991979E8B0> False\n",
      "<keras.layers.core.activation.Activation object at 0x0000029919791AC0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x00000299197ADFD0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000299197AD1C0> False\n",
      "<keras.layers.merging.add.Add object at 0x00000299197BA130> False\n",
      "<keras.layers.core.activation.Activation object at 0x00000299197B4AF0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x00000299197A5520> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000299197757C0> False\n",
      "<keras.layers.core.activation.Activation object at 0x00000299197A5190> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x00000299197438E0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002991974C610> False\n",
      "<keras.layers.core.activation.Activation object at 0x0000029919743BB0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x00000299197A5940> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x00000299197939A0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000299197970D0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000029919793280> False\n",
      "<keras.layers.merging.add.Add object at 0x000002991F8276A0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002991F827A60> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029919793880> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002991F82C850> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002991F831EE0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002991F8311C0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002991F837FA0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002991F82C490> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002991F837340> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002991F846B20> False\n",
      "<keras.layers.merging.add.Add object at 0x000002991F83FF70> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002991F84BCA0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002991F8513D0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002991F85A250> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002991F837820> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002991F85A0D0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000029920831D00> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002991F85A640> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x00000299208361F0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000029920843BB0> False\n",
      "<keras.layers.merging.add.Add object at 0x0000029920831760> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002992084AE50> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029920843B20> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000029920852BE0> False\n",
      "<keras.layers.core.activation.Activation object at 0x0000029920852AC0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029920858AF0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000299208605B0> False\n",
      "<keras.layers.core.activation.Activation object at 0x0000029920868430> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029920860EB0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000029920860A00> False\n",
      "<keras.layers.merging.add.Add object at 0x000002991F851070> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002991F8515E0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029919787520> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002991967B910> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002992083C220> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002992086D4F0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002992086DEE0> False\n",
      "<keras.layers.core.activation.Activation object at 0x00000299197BEAC0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002991F846280> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029920872EB0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002991F831C70> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000029920875F10> False\n",
      "<keras.layers.merging.add.Add object at 0x000002992087D970> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002992087D100> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029920879FD0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000299208727C0> False\n",
      "<keras.layers.core.activation.Activation object at 0x0000029920875E50> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x00000299208829D0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000029920889970> False\n",
      "<keras.layers.core.activation.Activation object at 0x00000299208826D0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002992087DCD0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000029920896820> False\n",
      "<keras.layers.merging.add.Add object at 0x000002992088FC10> False\n",
      "<keras.layers.core.activation.Activation object at 0x00000299208A5C70> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002992089D7F0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000299208AB940> False\n",
      "<keras.layers.core.activation.Activation object at 0x00000299208AB820> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x00000299208B23A0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000299208B21C0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002992089D940> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x00000299208A5B20> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000299208A5850> False\n",
      "<keras.layers.merging.add.Add object at 0x00000299208CB0A0> False\n",
      "<keras.layers.core.activation.Activation object at 0x00000299208CB820> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x00000299208D0430> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000299208DC370> False\n",
      "<keras.layers.core.activation.Activation object at 0x00000299208DCE50> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x00000299208DC880> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000299208C7AC0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002992089D2B0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x00000299208B8E80> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000299208D0CA0> False\n",
      "<keras.layers.merging.add.Add object at 0x00000299208C78B0> False\n",
      "<keras.layers.core.activation.Activation object at 0x0000029919758370> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002991F820130> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000029920860E20> False\n",
      "<keras.layers.core.activation.Activation object at 0x0000029920872670> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029920831160> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000299208BE8E0> False\n",
      "<keras.layers.core.activation.Activation object at 0x0000029920843040> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029920838BE0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000299208EE790> False\n",
      "<keras.layers.merging.add.Add object at 0x00000299208BE5E0> False\n",
      "<keras.layers.core.activation.Activation object at 0x00000299208F3AF0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x00000299208F1070> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000299208F8880> False\n",
      "<keras.layers.core.activation.Activation object at 0x0000029920900F10> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029920900D00> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000029920905940> False\n",
      "<keras.layers.core.activation.Activation object at 0x0000029920900190> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002992090EF40> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000029920915B50> False\n",
      "<keras.layers.merging.add.Add object at 0x000002992090EFA0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002992091A190> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002992091A1F0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002992092F1C0> False\n",
      "<keras.layers.core.activation.Activation object at 0x0000029920905D90> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x00000299209203A0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000029920900EB0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002991F846A00> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x00000299209202E0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002992094C2B0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000029920927280> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002992094CE20> False\n",
      "<keras.layers.merging.add.Add object at 0x000002992095E880> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002992095E130> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029920951FD0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000029920951DF0> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002992093CEB0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029920943640> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000029920943E50> False\n",
      "<keras.layers.core.activation.Activation object at 0x000002992093C490> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002992090EC10> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000029918F2DAF0> False\n",
      "<keras.layers.merging.add.Add object at 0x000002992091AE50> False\n",
      "<keras.layers.core.activation.Activation object at 0x00000299208BE280> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029920838B50> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000299208BEBB0> False\n",
      "<keras.layers.core.activation.Activation object at 0x00000299208F3B80> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029920905700> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002992088F2E0> False\n",
      "<keras.layers.core.activation.Activation object at 0x00000299208A5700> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002992096A8B0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000029920963700> False\n",
      "<keras.layers.merging.add.Add object at 0x00000299197934C0> False\n",
      "<keras.layers.core.activation.Activation object at 0x00000299208BE4C0> False\n",
      "<keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x000002992096ED30> False\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers[0].layers:\n",
    "\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20384\\2980021967.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  fit_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch_train, epochs=number_epochs,verbose=1, validation_data=validation_generator, validation_steps=steps_per_epoch_validation,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "24/24 [==============================] - 22s 765ms/step - loss: 0.9128 - accuracy: 0.8362 - val_loss: 0.8928 - val_accuracy: 0.8889\n",
      "Epoch 2/2\n",
      "24/24 [==============================] - 17s 709ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4226 - val_accuracy: 0.8889\n"
     ]
    }
   ],
   "source": [
    "fit_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch_train, epochs=number_epochs,verbose=1, validation_data=validation_generator, validation_steps=steps_per_epoch_validation,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/ResNet50/ResNet50_Product_Classification_2Dense.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\Vizuamatix\\Neural Network\\new.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Vizuamatix/Neural%20Network/new.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#save the model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Vizuamatix/Neural%20Network/new.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "#save the model\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "ResNet50_saved = load_model('model/ResNet50/ResNet50_Product_Classification_2Dense.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x2992104f940>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResNet50_saved.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 2048)              23587712  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              8392704   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 16388     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,996,804\n",
      "Trainable params: 8,409,092\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ResNet50_saved.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 941ms/step\n"
     ]
    }
   ],
   "source": [
    "#predicting\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "# load an image from file\n",
    "image = load_img('New folder/test/test.png', target_size=(224, 224))\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image = img_to_array(image)\n",
    "\n",
    "# reshape data for the model\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "# prepare the image for the VGG model\n",
    "image = preprocess_input(image)\n",
    "\n",
    "# predict the probability across all output classes\n",
    "yhat = ResNet50_saved.predict(image)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.9999976e-01, 8.0185835e-08, 3.9740991e-16, 1.4666466e-07],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "basemodel = Model(inputs=ResNet50_saved.input, outputs=ResNet50_saved.get_layer('dense').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n"
     ]
    }
   ],
   "source": [
    "#predicting\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "# load an image from file\n",
    "image1 = load_img('New folder/test/test4.jpg', target_size=(224, 224))\n",
    "image2 = load_img('New folder/test/test3.png', target_size=(224, 224))\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image1 = img_to_array(image1)\n",
    "image2 = img_to_array(image2)\n",
    "\n",
    "# reshape data for the model\n",
    "image1 = image1.reshape((1, image1.shape[0], image1.shape[1], image1.shape[2]))\n",
    "image2 = image2.reshape((1, image2.shape[0], image2.shape[1], image2.shape[2]))\n",
    "\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "# prepare the image for the VGG model\n",
    "image1 = preprocess_input(image1)\n",
    "image2 = preprocess_input(image2)\n",
    "\n",
    "# predict the probability across all output classes\n",
    "yhat1_base = basemodel.predict(image1)\n",
    "yhat2_base = basemodel.predict(image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9822604, 2.2466671, 0.       , ..., 0.       , 0.       ,\n",
       "        0.6798813]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat1_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.9701082\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "A = yhat1_base[0]\n",
    "B = yhat2_base[0]\n",
    "\n",
    "cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine)\n",
    "\n",
    "#VGG16 - 0.9403707\n",
    "#ResNet50 - 0.9701082"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n"
     ]
    }
   ],
   "source": [
    "#predicting\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "# load an image from file\n",
    "image1 = load_img('New folder/test/test2.jpg', target_size=(224, 224))\n",
    "image2 = load_img('New folder/test/test3.png', target_size=(224, 224))\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image1 = img_to_array(image1)\n",
    "image2 = img_to_array(image2)\n",
    "\n",
    "# reshape data for the model\n",
    "image1 = image1.reshape((1, image1.shape[0], image1.shape[1], image1.shape[2]))\n",
    "image2 = image2.reshape((1, image2.shape[0], image2.shape[1], image2.shape[2]))\n",
    "\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "# prepare the image for the VGG model\n",
    "image1 = preprocess_input(image1)\n",
    "image2 = preprocess_input(image2)\n",
    "\n",
    "# predict the probability across all output classes\n",
    "yhat1_base = basemodel.predict(image1)\n",
    "yhat2_base = basemodel.predict(image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.40083203\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "A = yhat1_base[0]\n",
    "B = yhat2_base[0]\n",
    "\n",
    "cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine)\n",
    "\n",
    "#VGG16 - 0.47206444\n",
    "#ResNet50 - 0.40083203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "Cosine Similarity: 0.8852835\n"
     ]
    }
   ],
   "source": [
    "#predicting\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "# load an image from file\n",
    "image1 = load_img('New folder/test/test.png', target_size=(224, 224))\n",
    "image2 = load_img('New folder/test/test3.png', target_size=(224, 224))\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image1 = img_to_array(image1)\n",
    "image2 = img_to_array(image2)\n",
    "\n",
    "# reshape data for the model\n",
    "image1 = image1.reshape((1, image1.shape[0], image1.shape[1], image1.shape[2]))\n",
    "image2 = image2.reshape((1, image2.shape[0], image2.shape[1], image2.shape[2]))\n",
    "\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "# prepare the image for the VGG model\n",
    "image1 = preprocess_input(image1)\n",
    "image2 = preprocess_input(image2)\n",
    "\n",
    "# predict the probability across all output classes\n",
    "yhat1_base = basemodel.predict(image1)\n",
    "yhat2_base = basemodel.predict(image2)\n",
    "\n",
    "A = yhat1_base[0]\n",
    "B = yhat2_base[0]\n",
    "\n",
    "cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "Cosine Similarity: 0.56222504\n"
     ]
    }
   ],
   "source": [
    "#predicting\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "# load an image from file\n",
    "image1 = load_img('New folder/test/test5.png', target_size=(224, 224))\n",
    "image2 = load_img('New folder/test/test3.png', target_size=(224, 224))\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image1 = img_to_array(image1)\n",
    "image2 = img_to_array(image2)\n",
    "\n",
    "# reshape data for the model\n",
    "image1 = image1.reshape((1, image1.shape[0], image1.shape[1], image1.shape[2]))\n",
    "image2 = image2.reshape((1, image2.shape[0], image2.shape[1], image2.shape[2]))\n",
    "\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "# prepare the image for the VGG model\n",
    "image1 = preprocess_input(image1)\n",
    "image2 = preprocess_input(image2)\n",
    "\n",
    "# predict the probability across all output classes\n",
    "yhat1_base = basemodel.predict(image1)\n",
    "yhat2_base = basemodel.predict(image2)\n",
    "\n",
    "A = yhat1_base[0]\n",
    "B = yhat2_base[0]\n",
    "\n",
    "cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Cosine Similarity: 0.76314044\n"
     ]
    }
   ],
   "source": [
    "#predicting\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "# load an image from file\n",
    "image1 = load_img('New folder/test/test2.jpg', target_size=(224, 224))\n",
    "image2 = load_img('New folder/test/test5.png', target_size=(224, 224))\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image1 = img_to_array(image1)\n",
    "image2 = img_to_array(image2)\n",
    "\n",
    "# reshape data for the model\n",
    "image1 = image1.reshape((1, image1.shape[0], image1.shape[1], image1.shape[2]))\n",
    "image2 = image2.reshape((1, image2.shape[0], image2.shape[1], image2.shape[2]))\n",
    "\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "# prepare the image for the VGG model\n",
    "image1 = preprocess_input(image1)\n",
    "image2 = preprocess_input(image2)\n",
    "\n",
    "# predict the probability across all output classes\n",
    "yhat1_base = basemodel.predict(image1)\n",
    "yhat2_base = basemodel.predict(image2)\n",
    "\n",
    "A = yhat1_base[0]\n",
    "B = yhat2_base[0]\n",
    "\n",
    "cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "Cosine Similarity: 0.92447865\n"
     ]
    }
   ],
   "source": [
    "#predicting\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "# load an image from file\n",
    "image1 = load_img('New folder/test/test6.jpg', target_size=(224, 224))\n",
    "image2 = load_img('New folder/test/test5.png', target_size=(224, 224))\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image1 = img_to_array(image1)\n",
    "image2 = img_to_array(image2)\n",
    "\n",
    "# reshape data for the model\n",
    "image1 = image1.reshape((1, image1.shape[0], image1.shape[1], image1.shape[2]))\n",
    "image2 = image2.reshape((1, image2.shape[0], image2.shape[1], image2.shape[2]))\n",
    "\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "# prepare the image for the VGG model\n",
    "image1 = preprocess_input(image1)\n",
    "image2 = preprocess_input(image2)\n",
    "\n",
    "# predict the probability across all output classes\n",
    "yhat1_base = basemodel.predict(image1)\n",
    "yhat2_base = basemodel.predict(image2)\n",
    "\n",
    "A = yhat1_base[0]\n",
    "B = yhat2_base[0]\n",
    "\n",
    "cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "Cosine Similarity: 0.9828984\n"
     ]
    }
   ],
   "source": [
    "#predicting\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "# load an image from file\n",
    "image1 = load_img('New folder/test/test7.jpeg', target_size=(224, 224))\n",
    "image2 = load_img('New folder/test/test5.png', target_size=(224, 224))\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image1 = img_to_array(image1)\n",
    "image2 = img_to_array(image2)\n",
    "\n",
    "# reshape data for the model\n",
    "image1 = image1.reshape((1, image1.shape[0], image1.shape[1], image1.shape[2]))\n",
    "image2 = image2.reshape((1, image2.shape[0], image2.shape[1], image2.shape[2]))\n",
    "\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "# prepare the image for the VGG model\n",
    "image1 = preprocess_input(image1)\n",
    "image2 = preprocess_input(image2)\n",
    "\n",
    "# predict the probability across all output classes\n",
    "yhat1_base = basemodel.predict(image1)\n",
    "yhat2_base = basemodel.predict(image2)\n",
    "\n",
    "A = yhat1_base[0]\n",
    "B = yhat2_base[0]\n",
    "\n",
    "cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "Cosine Similarity: 0.5496688\n"
     ]
    }
   ],
   "source": [
    "#predicting\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "# load an image from file\n",
    "image1 = load_img('New folder/test/test7.jpeg', target_size=(224, 224))\n",
    "image2 = load_img('New folder/test/test3.png', target_size=(224, 224))\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image1 = img_to_array(image1)\n",
    "image2 = img_to_array(image2)\n",
    "\n",
    "# reshape data for the model\n",
    "image1 = image1.reshape((1, image1.shape[0], image1.shape[1], image1.shape[2]))\n",
    "image2 = image2.reshape((1, image2.shape[0], image2.shape[1], image2.shape[2]))\n",
    "\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "# prepare the image for the VGG model\n",
    "image1 = preprocess_input(image1)\n",
    "image2 = preprocess_input(image2)\n",
    "\n",
    "# predict the probability across all output classes\n",
    "yhat1_base = basemodel.predict(image1)\n",
    "yhat2_base = basemodel.predict(image2)\n",
    "\n",
    "A = yhat1_base[0]\n",
    "B = yhat2_base[0]\n",
    "\n",
    "cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Cosine Similarity: 0.6096772\n"
     ]
    }
   ],
   "source": [
    "#predicting\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "# load an image from file\n",
    "image1 = load_img('New folder/test/test5.png', target_size=(224, 224))\n",
    "image2 = load_img('New folder/test/test4.jpg', target_size=(224, 224))\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image1 = img_to_array(image1)\n",
    "image2 = img_to_array(image2)\n",
    "\n",
    "# reshape data for the model\n",
    "image1 = image1.reshape((1, image1.shape[0], image1.shape[1], image1.shape[2]))\n",
    "image2 = image2.reshape((1, image2.shape[0], image2.shape[1], image2.shape[2]))\n",
    "\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "# prepare the image for the VGG model\n",
    "image1 = preprocess_input(image1)\n",
    "image2 = preprocess_input(image2)\n",
    "\n",
    "# predict the probability across all output classes\n",
    "yhat1_base = basemodel.predict(image1)\n",
    "yhat2_base = basemodel.predict(image2)\n",
    "\n",
    "A = yhat1_base[0]\n",
    "B = yhat2_base[0]\n",
    "\n",
    "cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine)\n",
    "#0.56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a90aeebcf29d64a654773811cc170cb25061cb2498f10ac689db374c7bf325de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
